Code for downloading the data
Create script
#!/usr/bin/env bash
set -euo pipefail

mkdir -p data/fastq

SRRS=(
  SRR10551665 SRR10551664 SRR10551663   # Early biofilm
  SRR10551662 SRR10551661 SRR10551660   # Thin biofilm
  SRR10551659 SRR10551658 SRR10551657   # Mature biofilm
)

for srr in "${SRRS[@]}"; do
  echo "=== Downloading ${srr} ==="
  fasterq-dump "${srr}" --split-files -O data/fastq
done

echo "=== Compressing FASTQ files ==="
gzip -f data/fastq/*.fastq

Run script
./scripts/01_download_sra.sh

Script failed to download SRR10551658/57, so this code was run to download those final two files
micromamba activate a2
mkdir -p data/sra

# download locally
prefetch SRR10551658 -O data/sra

# convert to FASTQ
fasterq-dump data/sra/SRR10551658 -O data/fastq --split-files

# compress
gzip -f data/fastq/SRR10551658*.fastq

Repeated for 57, dont need the previous two steps since it 58 was the only one to encounter an error while the script was running
fasterq-dump SRR10551657 -O data/fastq --split-files
gzip -f data/fastq/SRR10551657*.fastq


*A version of the previous script with the second method built in as a redundancy*
cat > scripts/01_download_sra.sh << 'EOF'
#!/usr/bin/env bash
set -u  # note: not using -e on purpose so we can handle failures manually
set -o pipefail

mkdir -p data/fastq data/sra

SRRS=(
  SRR10551665 SRR10551664 SRR10551663
  SRR10551662 SRR10551661 SRR10551660
  SRR10551659 SRR10551658 SRR10551657
)

download_one () {
  local srr="$1"
  echo "=== Downloading ${srr} ==="

  # Try direct fastq conversion
  if fasterq-dump "${srr}" --split-files -O data/fastq; then
    gzip -f data/fastq/${srr}*.fastq
    return 0
  fi

  echo "Direct fasterq-dump failed for ${srr}; trying prefetch fallback..."
  prefetch "${srr}" -O data/sra
  fasterq-dump "data/sra/${srr}" --split-files -O data/fastq
  gzip -f data/fastq/${srr}*.fastq
}

for srr in "${SRRS[@]}"; do
  download_one "${srr}"
done

echo "All downloads complete."
EOF

chmod +x scripts/01_download_sra.sh


Quality check script
cat > scripts/02_qc.sh << 'EOF'
#!/usr/bin/env bash
set -euo pipefail

mkdir -p results/qc

# Run FastQC on all FASTQ files
fastqc data/fastq/*.fastq.gz -o results/qc

# Summarize with MultiQC
multiqc results/qc -o results/qc
EOF

chmod +x scripts/02_qc.sh

Run script
./scripts/02_qc.sh


Download yeast reference (ensembl)
micromamba activate a2

mkdir -p reference
cd reference

# Download transcriptome
wget https://ftp.ensembl.org/pub/release-111/fasta/saccharomyces_cerevisiae/cdna/Saccharomyces_cerevisiae.R64-1-1.cdna.all.fa.gz

# Download gene annotation
wget https://ftp.ensembl.org/pub/release-111/gtf/saccharomyces_cerevisiae/Saccharomyces_cerevisiae.R64-1-1.111.gtf.gz

# Decompress transcript FASTA
gunzip Saccharomyces_cerevisiae.R64-1-1.cdna.all.fa.gz


Construct salmon index
# remove any partially-created index folder (safe)
rm -rf reference/salmon_index

# build index (modern Salmon default / pufferfish)
salmon index \
  -t reference/Saccharomyces_cerevisiae.R64-1-1.cdna.all.fa \
  -i reference/salmon_index \
  -k 31


Salmon Quantification
cat > scripts/03_salmon_quant.sh << 'EOF'
#!/usr/bin/env bash
set -euo pipefail

INDEX="reference/salmon_index"
FASTQ_DIR="data/fastq"
OUT_DIR="results/salmon"

mkdir -p ${OUT_DIR}

for fq in ${FASTQ_DIR}/*.fastq.gz; do
  sample=$(basename ${fq} .fastq.gz)
  echo "Quantifying ${sample}"

  salmon quant \
    -i ${INDEX} \
    -l A \
    -r ${fq} \
    --validateMappings \
    --gcBias \
    --seqBias \
    --posBias \
    --fldMean 200 \
    --fldSD 20 \
    -o ${OUT_DIR}/${sample}
done
EOF

chmod +x scripts/03_salmon_quant.sh

./scripts/03_salmon_quant.sh



